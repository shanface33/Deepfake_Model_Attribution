# Deepfake_Model_Attribution
Codes and dataset (DFDM) for Model Attribution of Face-swap Deepfake Videos 


We created a new dataset, named DFDM, with 6,450 Deepfake videos generated by different Autoencoder models. Specifically, five Autoencoder models with variations in encoder, decoder, intermediate layer, and input resolution, respectively, have been selected to generate Deepfakes based on the same input. We first observe the visual differences among different Deepfakes, demonstrating the evidence of model attribution artifacts. Then we take Deepfakes model attribution as a multiclass classification task and propose a spatial and temporal attention based method to explore the differences among Deepfakes in the new dataset.

## Dataset Summary 
![fig1_compressed-1](Fig1.jpg)
| Model | Input | Output | Encoder | Decoder | Variation| 
| :-------------------: | :-----: | :-----: | :---------: | :---------: | :---------: |
|  Faceswap (baseline)  |   64    |   64    |  4Conv+1Ups |  3Ups+1Conv |  /
|  Lightweight          |   64    |   64    |  3Conv+1Ups |  3Ups+1Conv |  Encoder|  
|  IAE                  |   64    |   64    |  4Conv      |  4Ups+1Conv |  Intermediate layers; Shared Encoder&Decoder|  
|  Dfaker               |   64    |   128   |  4Conv+1Ups | 4Ups+3Residual+1Conv |  Decoder|  
|  DFL-H128             |  128    |  128    |  4Conv+1Ups |  3Ups+1Conv |  Input resolution|  


### Download
If you would like to access the DFDM dataset, please fill out this [google form](https://docs.google.com/forms/d/e/1FAIpQLSeM-1pJ13RyPVgF0bGRQtLiupwWDvALD6rKa_Oa8sIluIqtSA/viewform?usp=sf_link). The download link will be sent to you once the form is accepted. If you have any questions, please send email to [dfdmdataset@gmail.com]
