# Deepfake_Model_Attribution
Codes and dataset (DFDM) for Model Attribution of Face-swap Deepfake Videos 


We created a new dataset, named DFDM, with 6,450 Deepfake videos generated by different Autoencoder models. Specifically, five Autoencoder models with variations in encoder, decoder, intermediate layer, and input resolution, respectively, have been selected to generate Deepfakes based on the same input. We first observe the visual differences among different Deepfakes, demonstrating the evidence of model attribution artifacts. Then we take Deepfakes model attribution as a multiclass classification task and propose a spatial and temporal attention based method to explore the differences among Deepfakes in the new dataset.

## Dataset Summary 
![fig1_compressed-1](Fig.png)
| Model | Input | Output | Encoder | Decoder | Variation| 
| :-------------------: | :-----: | :-----: | :---------: | :---------: | :---------: |
|  Faceswap (baseline)  |   64    |   64    |  4Conv+1Ups |  3Ups+1Conv |  /
|  Lightweight          |   64    |   64    |  3Conv+1Ups |  3Ups+1Conv |  Encoder|  
|  IAE                  |   64    |   64    |  4Conv      |  4Ups+1Conv |  Intermediate layers; Shared Encoder&Decoder|  
|  Dfaker               |   64    |   128   |  4Conv+1Ups | 4Ups+3Residual+1Conv |  Decoder|  
|  DFL-H128             |  128    |  128    |  4Conv+1Ups |  3Ups+1Conv |  Input resolution|  
